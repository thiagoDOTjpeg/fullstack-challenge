# Fullstack Challenge - Sistema de Gerenciamento de Tarefas

## ğŸ“ Arquitetura

```mermaid
graph TB
    subgraph "Cliente"
        FE[Frontend React]
    end

    subgraph "API Layer"
        GW[API Gateway<br/>NestJS - :3000]
    end

    subgraph "MicrosserviÃ§os"
        AUTH[Auth Service<br/>NestJS - :3001]
        TASK[Task Service<br/>NestJS - :3002]
        NOTIF[Notification Service<br/>NestJS - :3003]
    end

    subgraph "Infraestrutura"
        PG[(PostgreSQL<br/>:5432)]
        RMQ[RabbitMQ<br/>:5672/:15672]
    end

    subgraph "Schemas PostgreSQL"
        AUTH_SCHEMA[auth_service]
        TASK_SCHEMA[task_service]
        NOTIF_SCHEMA[notification_service]
    end

    FE -->|HTTP/REST| GW
    GW -->|TCP/RPC| AUTH
    GW -->|TCP/RPC| TASK

    TASK -.->|Async Event| RMQ
    RMQ -.->|Consumer| NOTIF

    AUTH --> AUTH_SCHEMA
    TASK --> TASK_SCHEMA
    NOTIF --> NOTIF_SCHEMA

    AUTH_SCHEMA --> PG
    TASK_SCHEMA --> PG
    NOTIF_SCHEMA --> PG

    style FE fill:#61dafb,stroke:#333,stroke-width:2px,color:#000
    style GW fill:#e535ab,stroke:#333,stroke-width:2px,color:#000
    style AUTH fill:#ffd43b,stroke:#333,stroke-width:2px,color:#000
    style TASK fill:#ffd43b,stroke:#333,stroke-width:2px,color:#000
    style NOTIF fill:#ffd43b,stroke:#333,stroke-width:2px,color:#000
    style PG fill:#336791,stroke:#333,stroke-width:2px,color:#fff
    style RMQ fill:#ff6600,stroke:#333,stroke-width:2px,color:#000
```

### Fluxo de Dados

1. **RequisiÃ§Ãµes SÃ­ncronas (TCP)**: Frontend â†’ Gateway â†’ Auth/Task Services
2. **Eventos AssÃ­ncronos (RabbitMQ)**: Task Service â†’ Queue â†’ Notification Service

---

```mermaid
erDiagram
    %% ==========================================
    %% SCHEMA: auth_service
    %% ==========================================
    users {
        uuid id PK
        varchar email UK
        varchar name
        varchar password_hash
        varchar refresh_token_hash
        timestamp created_at
        timestamp updated_at
    }

    %% ==========================================
    %% SCHEMA: task_service
    %% ==========================================
    tasks {
        uuid id PK
        varchar title
        text description
        enum status "pending, in_progress, completed"
        enum priority "low, medium, high"
        uuid assigned_to FK "LOGICAL: auth_service.users.id"
        timestamp due_date
        timestamp created_at
        timestamp updated_at
    }

    task_history {
        uuid id PK
        uuid task_id FK
        uuid user_id FK "LOGICAL: auth_service.users.id"
        varchar field_changed
        text old_value
        text new_value
        timestamp changed_at
    }

    task_comments {
        uuid id PK
        uuid task_id FK
        uuid user_id FK "LOGICAL: auth_service.users.id"
        text content
        timestamp created_at
        timestamp updated_at
    }

    %% ==========================================
    %% SCHEMA: notification_service
    %% ==========================================
    notifications {
        uuid id PK
        uuid user_id FK "LOGICAL: auth_service.users.id"
        varchar type
        varchar title
        text message
        jsonb metadata
        boolean is_read
        timestamp created_at
        timestamp read_at
    }

    %% Relacionamentos DENTRO do mesmo schema (Physical FK)
    tasks ||--o{ task_history : "has"
    tasks ||--o{ task_comments : "has"

    %% Relacionamentos CROSS-SCHEMA (Logical Reference - dotted lines)
    tasks }o..|| users : "assigned_to (logical)"
    task_history }o..|| users : "changed_by (logical)"
    task_comments }o..|| users : "created_by (logical)"
    notifications }o..|| users : "belongs_to (logical)"
```

## ğŸ“Š Detalhes dos Schemas

### ğŸ” auth_service (Auth Service)

- **users**: Armazena credenciais e tokens de autenticaÃ§Ã£o
  - `password_hash`: Senha criptografada com bcrypt
  - `refresh_token_hash`: Token hash para renovaÃ§Ã£o de sessÃ£o
  - `email`: Ãšnico (constraint)
  - `username`: Ãšnico (constraint)

### ğŸ“‹ task_service (Task Service)

- **tasks**: Entidade principal de tarefas
  - `status`: ENUM (pending | in_progress | completed)
  - `priority`: ENUM (low | medium | high)
  - `assigned_to`: FK para users (cross-schema reference)

- **task_history**: Auditoria de alteraÃ§Ãµes
  - Registra quem mudou, qual campo e valores antigo/novo

- **task_comments**: Sistema de comentÃ¡rios
  - ReferÃªncias cross-schema para users

### ğŸ”” notification_service (Notification Service)

- **notifications**: NotificaÃ§Ãµes assÃ­ncronas
  - `metadata`: JSONB para dados flexÃ­veis do evento
  - `is_read`: Flag de leitura
  - `user_id`: FK cross-schema para users

## ğŸ”— Cross-Schema References

> **Nota**: Embora os schemas sejam isolados, as FKs para `users` sÃ£o **referÃªncias lÃ³gicas** (via UUID). O TypeORM nÃ£o cria constraints fÃ­sicas entre schemas diferentes, mantendo o desacoplamento dos microsserviÃ§os pois seriam banco de dados separados.

---

## ğŸ§  DecisÃµes TÃ©cnicas e Trade-offs

### 1. Arquitetura de ComunicaÃ§Ã£o HÃ­brida (TCP + RabbitMQ)

**DecisÃ£o**: NÃ£o usei apenas um protocolo de comunicaÃ§Ã£o.

- **Gateway â†” Auth/Tasks**: TCP (SÃ­ncrono/RPC)
- **Tasks â Notifications**: RabbitMQ (AssÃ­ncrono/Eventos)

**Justificativa**:
Decidi usar uma abordagem hÃ­brida para priorizar a **ExperiÃªncia do UsuÃ¡rio (UX)**. Para operaÃ§Ãµes como login e listagem de tarefas, o usuÃ¡rio estÃ¡ esperando na tela, entÃ£o usei TCP que Ã© mais rÃ¡pido e direto (sem overhead de HTTP). JÃ¡ para as notificaÃ§Ãµes, que sÃ£o efeitos colaterais e nÃ£o podem travar o fluxo principal, usei RabbitMQ para garantir desacoplamento e resiliÃªncia.

**Trade-offs**:

- âœ… Melhor performance em operaÃ§Ãµes crÃ­ticas
- âœ… ResiliÃªncia em operaÃ§Ãµes assÃ­ncronas
- âŒ Maior complexidade de infraestrutura (2 tipos de comunicaÃ§Ã£o)

---

### 2. IsolaÃ§Ã£o de Dados via Schemas do PostgreSQL

**DecisÃ£o**: Usei um Ãºnico container de banco de dados, mas criei schemas diferentes (`auth_service`, `task_service`, `notification_service`) para cada microsserviÃ§o.

**Justificativa**:
Embora a teoria pura de microsserviÃ§os diga "um banco por serviÃ§o", manter 3 instÃ¢ncias de Postgres rodando localmente consumiria muita memÃ³ria e complicaria a infraestrutura do teste. O uso de Schemas me deu o **isolamento lÃ³gico** necessÃ¡rio (um serviÃ§o nÃ£o acessa a tabela do outro) com a simplicidade operacional de gerenciar apenas uma instÃ¢ncia de banco.

**Trade-offs**:

- âœ… Menor consumo de recursos (RAM/CPU)
- âœ… Setup mais simples
- âœ… Isolamento lÃ³gico mantido
- âŒ PossÃ­vel ponto Ãºnico de falha (em produÃ§Ã£o, seria separado)

---

### 3. OrquestraÃ§Ã£o de Startup e Health Checks (Docker)

**DecisÃ£o**: Configurei `healthcheck` no Postgres e RabbitMQ, e usei `depends_on: service_healthy` nos microsserviÃ§os. TambÃ©m coloquei a execuÃ§Ã£o das Migrations no comando de startup.

**Justificativa**:
Queria uma experiÃªncia de **"Zero ConfiguraÃ§Ã£o"** para quem for rodar o projeto. Resolvi o problema clÃ¡ssico de **Race Condition** (onde a app tenta conectar antes do banco estar pronto) garantindo que o Docker sÃ³ inicie a aplicaÃ§Ã£o quando a infraestrutura estiver saudÃ¡vel. As migrations automÃ¡ticas garantem que o banco esteja sempre na versÃ£o correta do cÃ³digo.

**Trade-offs**:

- âœ… Setup automÃ¡tico (`docker-compose up` e pronto)
- âœ… Zero race conditions
- âœ… Migrations sempre aplicadas
- âŒ Startup inicial um pouco mais lento (aguarda health checks)

---

## âš ï¸ Problemas Conhecidos e Melhorias Futuras

### Problemas Conhecidos

1. **Sem retry policy nas filas**: Se o Notification Service falhar ao processar uma mensagem, ela Ã© perdida
2. **AutenticaÃ§Ã£o bÃ¡sica**: JWT stateless (dificulta revogaÃ§Ã£o imediata)

### O que Melhoraria com Mais Tempo

- [ ] **GestÃ£o de SessÃ£o com Redis**: Implementar controle de sessÃ£o para mitigar _Race Conditions_ e _Replay Attacks_, alÃ©m de permitir _Blacklist_ para revogaÃ§Ã£o de tokens.
- [ ] Implementar Circuit Breaker pattern nas comunicaÃ§Ãµes TCP
- [ ] Adicionar observabilidade (Prometheus + Grafana)
- [ ] Implementar testes E2E com Cypress
- [ ] Cache com Redis para listagem de tarefas
- [ ] Dead Letter Queue (DLQ) no RabbitMQ
- [ ] CI/CD com GitHub Actions
- [ ] DocumentaÃ§Ã£o Swagger/OpenAPI completa

---

## â±ï¸ Tempo Gasto (WakaTime Data)

O desenvolvimento totalizou **49 horas**, com foco intensivo na robustez da infraestrutura e na lÃ³gica de sincronizaÃ§Ã£o entre os serviÃ§os.

| Ãrea de Desenvolvimento        | Tempo Real  |                                 |
| :----------------------------- | :---------- | :------------------------------ |
| **Frontend (React + UI)**      | 16h 30m     |
| **Infraestrutura (Docker)**    | 7h 00m      |
| **Task Service (Core Logic)**  | 8h 15m      |
| **Auth Service & Gateway**     | 6h 30m      |
| **Notification Service (RMQ)** | 4h 30m      |
| **RefatoraÃ§Ã£o & Testes**       | 4h 20m      |
| **DocumentaÃ§Ã£o & Setup**       | 2h 00m      |
| **TOTAL GERAL**                | **49h 05m** | **Dados extraÃ­dos do WakaTime** |

---

## ğŸ“‚ Estrutura do Projeto

O projeto utiliza **Turborepo** para gerenciamento do monorepo:

```bash
fullstack-challenge
â”œâ”€â”€ apps/                               # ğŸ“¦ AplicaÃ§Ãµes e ServiÃ§os
â”‚   â”œâ”€â”€ api-gateway/                    # Entrypoint HTTP (NestJS)
â”‚   â”‚   â”œâ”€â”€ src/common/filters/         # Filtros para converter erros RPC -> HTTP
â”‚   â”‚   â””â”€â”€ src/[modules]/              # Controllers que roteiam para os microsserviÃ§os
â”‚   â”‚
â”‚   â”œâ”€â”€ auth-service/                   # MicrosserviÃ§o de AutenticaÃ§Ã£o (TCP)
â”‚   â”‚   â”œâ”€â”€ db/migrations/              # Migrations exclusivas do schema 'auth_service'
â”‚   â”‚   â””â”€â”€ src/auth/                   # LÃ³gica de JWT e Hash de Senha
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks-service/                  # MicrosserviÃ§o Core (HÃ­brido: TCP + RabbitMQ)
â”‚   â”‚   â”œâ”€â”€ db/migrations/              # Migrations do schema 'task_service'
â”‚   â”‚   â”œâ”€â”€ src/history/                # LÃ³gica de Auditoria (Audit Log)
â”‚   â”‚   â””â”€â”€ src/task/                   # CRUD e PublicaÃ§Ã£o de Eventos
â”‚   â”‚
â”‚   â”œâ”€â”€ notifications-service/          # MicrosserviÃ§o de NotificaÃ§Ãµes (RabbitMQ Consumer)
â”‚   â”‚   â”œâ”€â”€ src/notifications.gateway.ts # WebSocket Gateway (Socket.io)
â”‚   â”‚   â””â”€â”€ src/notifications/          # Consumo de filas e disparo de eventos
â”‚   â”‚
â”‚   â””â”€â”€ web/                            # Frontend (React + Vite + TanStack)
â”‚       â”œâ”€â”€ src/components/ui/          # Componentes Shadcn/UI
â”‚       â”œâ”€â”€ src/hooks/                  # Custom Hooks (React Query + WebSocket)
â”‚       â”œâ”€â”€ src/services/               # Camada de API (Axios)
â”‚       â””â”€â”€ src/pages/                  # Rotas da aplicaÃ§Ã£o (Kanban, Login)
â”‚
â”œâ”€â”€ packages/                           # ğŸ› ï¸ Bibliotecas Compartilhadas (Shared Libs)
â”‚   â”œâ”€â”€ types/                          # 'Source of Truth': DTOs, Enums e Interfaces
â”‚   â”‚   â”œâ”€â”€ dto/                        # Objetos de transferÃªncia de dados
â”‚   â”‚   â””â”€â”€ payloads/                   # Payloads de eventos RabbitMQ/JWT
â”‚   â”œâ”€â”€ exceptions/                     # PadronizaÃ§Ã£o de erros entre serviÃ§os
â”‚   â””â”€â”€ eslint-config/                  # Regras de Linting compartilhadas
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ seed.ts                         # Script para popular o banco de dados
â”‚
â”œâ”€â”€ docker-compose.yml                  # OrquestraÃ§Ã£o da Infraestrutura
â””â”€â”€ turbo.json                          # Pipeline de Build do Monorepo
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker & Docker Compose
- Node.js 18+ (para desenvolvimento local)

### Rodar o Projeto

```bash
# Clonar o repositÃ³rio
git clone <repository-url>
cd fullstack-challenge

# Subir toda a infraestrutura
docker compose up -d --build

# Acessar a aplicaÃ§Ã£o
# Frontend: http://localhost:5173
# RabbitMQ Management: http://localhost:15672 (guest/guest)
```

---

## ğŸ”§ VariÃ¡veis de Ambiente

Todas as variÃ¡veis estÃ£o no `docker-compose.yml` para facilitar o teste. Em produÃ§Ã£o, usar `.env` e secrets.

---

## ğŸ“š Stack TecnolÃ³gica

- **Backend**: NestJS, TypeScript, TypeORM
- **Frontend**: React, Vite, TailwindCSS
- **Banco de Dados**: PostgreSQL
- **Message Broker**: RabbitMQ
- **ContainerizaÃ§Ã£o**: Docker, Docker Compose
- **Testes**: Jest (Backend)

### ğŸŒ± Populando o Banco de Dados

Para testar o projeto com dados reais, execute o script de seed (com os containers rodando):

```bash
# Instala dependÃªncias do script (caso necessÃ¡rio)
npm install

# Executa o seed
npm run seed
```

---

### ğŸ“– DocumentaÃ§Ã£o da API

ApÃ³s subir os containers, a documentaÃ§Ã£o interativa (Swagger/OpenAPI) estarÃ¡ disponÃ­vel em:

ğŸ‘‰ **[http://localhost:3001/api/docs](http://localhost:3001/api/docs)**

---

## ğŸ”§ Troubleshooting (ResoluÃ§Ã£o de Problemas)

**1. Erro: "Port already in use"**
Garanta que as portas `3000`, `3001`, `5432` e `5672` estejam livres.

```bash
docker compose down -v
```
